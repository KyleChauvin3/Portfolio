# Community Clinic Forecasting: Dollars Per Clinic By Day
# Kyle Chauvin
#################################################################################
#################################################################################
rm(list = ls())
# mypaths <- .libPaths()
# mypaths <- c(mypaths[2],mypaths[1])
# .libPaths(mypaths)

# QUERY_START_TIME <- Sys.time()

options(scipen = 100);options(max.print = 10000)
library(readxl);library(dplyr);library(caret);library(ggplot2);library(lattice);
library(rpart);library(lubridate);library(Metrics);library(glmnet);library(Matrix);
library(caret);library(kableExtra);library(class);library(openxlsx);library(gmodels);
library(MASS);library(reshape2);library(tidyr);library(ggpubr);library(tibble);
library(stringr);library(sqldf);library(car);library(ggpubr);library(tidyverse);
library(stringr);library(data.table);library(readxl);library(factoextra);library(writexl);
library(cluster);library(corrplot);library(tidyverse);library(mapsapi);library(lmtest);
library(dbplyr);library(DBI);library(odbc);library(xgboost);library(gridExtra);
library(tidyverse);library(keras);library(arrow);library(tidymodels);library(doFuture);
library(vip);library(gdata);library(xml2);library(tensorflow);library(tseries);
library(zoo);library(forecast);library(tidyverse);library(tidymodels);library(modeltime);
library(timetk);library(moments);
# ################################################################################################################
set.seed(123)


data <- read_excel("C:/Users/kyle.chauvin/OneDrive - PetIQ, LLC/.KC/Services 30-60-90/Forecasting Code/TimeSeriesData.xlsx",
                   sheet = "Community Clinics")
data <- data %>% rename(cancellation_rate = `Cancellation Rate`)

filtered_data <- data[,c(1,6)]
filtered_data$Pets <- na.approx(filtered_data$Pets)
# filtered_data$date <- as.Date(as.yearmon(filtered_data$date))
# filtered_data <- filtered_data %>% filter(date >='2018-01-01') 

filtered_data %>%
  plot_time_series(date, Pets, .interactive = FALSE)

splits <- filtered_data %>%
  time_series_split(assess = "4 months", cumulative = TRUE)

splits %>%
  tk_time_series_cv_plan() %>%
  plot_time_series_cv_plan(date, Pets, .interactive = FALSE)

#ARIMA
model_fit_arima <- arima_reg() %>%
  set_engine("auto_arima") %>%
  fit(Pets ~ date, training(splits))
model_fit_arima

#PROPHET
model_fit_prophet <- prophet_reg() %>%
  set_engine("prophet") %>%
  fit(Pets ~ date, training(splits))
model_fit_prophet




recipe_spec <- recipe(Pets ~ date, training(splits)) %>%
  step_timeseries_signature(date) %>%
  step_rm(contains("am.pm"), contains("hour"), contains("minute"),
          contains("second"), contains("xts")) %>%
  step_fourier(date, period = 364.25, K=5) %>%
  step_dummy(all_nominal())
recipe_spec %>% prep() %>% juice()


model_spec_glmnet <- linear_reg(penalty = 0.01, mixture = 0.5) %>%
  set_engine("glmnet")
workflow_fit_glmnet <- workflow() %>%
  add_model(model_spec_glmnet) %>%
  add_recipe(recipe_spec %>% step_rm(date)) %>%
  fit(training(splits))


model_spec_rf <- rand_forest(trees = 500, min_n = 50) %>%
  set_engine("randomForest") %>% 
  set_mode("regression")
workflow_fit_rf <- workflow() %>%
  add_model(model_spec_rf) %>%
  add_recipe(recipe_spec %>% step_rm(date)) %>%
  fit(training(splits))


model_spec_prophet_boost <- prophet_boost() %>%
  set_engine("prophet_xgboost") 
workflow_fit_prophet_boost <- workflow() %>%
  add_model(model_spec_prophet_boost) %>%
  add_recipe(recipe_spec) %>%
  fit(training(splits))
workflow_fit_prophet_boost


model_table <- modeltime_table(
  model_fit_arima, 
  model_fit_prophet,
  workflow_fit_glmnet,
  workflow_fit_rf,
  workflow_fit_prophet_boost) 
model_table


calibration_table <- model_table %>%
  modeltime_calibrate(testing(splits))
calibration_table


calibration_table %>%
  modeltime_accuracy() %>%
  table_modeltime_accuracy(.interactive = FALSE)
# 
calibration_table %>%
  filter(.model_id ==4) %>%
  modeltime_forecast(actual_data = filtered_data) %>%
  plot_modeltime_forecast(.interactive = TRUE)

print(
  as.data.frame(
    calibration_table %>%
      filter(.model_id ==4) %>%
      # filter(!.model_id %in% c(1,3,4,5)) %>%
      modeltime_forecast(actual_data = filtered_data)
  )
  ,n=nrow(500))

temp1 <-
  as.data.frame(
    calibration_table %>%
      filter(.model_id ==4) %>%
      modeltime_forecast(actual_data = filtered_data))

temp1 <- temp1 %>% filter(.index > "2023-10-01")

write.csv(temp1,"C:/Users/kyle.chauvin/OneDrive - PetIQ, LLC/.KC/Services 30-60-90/Forecasting Code/Data Validation/CC Pets.csv")


# 
calibration_table %>%
  filter(.model_id ==4) %>%
  # filter(!.model_id %in% c(1,3,4,5)) %>%
  modeltime_refit(filtered_data) %>%
  modeltime_forecast(h = "4 months",
                     conf_interval = 0.95,
                     actual_data = filtered_data) %>%
  plot_modeltime_forecast(.interactive = TRUE)
# 
# 
predictions <-
  as.data.frame(
    calibration_table %>%
      filter(.model_id ==4) %>%
      # filter(!.model_id %in% c(1,3,4,5)) %>%
      modeltime_refit(filtered_data) %>%
      modeltime_forecast(h = "4 months",
                         conf_interval = 0.95,
                         actual_data = filtered_data)
  )

write.csv(predictions,"C:/Users/kyle.chauvin/OneDrive - PetIQ, LLC/.KC/Services 30-60-90/Forecasting Code/Predictions/CC Pets.csv")
